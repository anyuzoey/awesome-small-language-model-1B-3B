# Efficient (Agentic) Models: Preliminary Literature Search 
This project explores small-scale, efficient LLMs (1B-3B parameters, ideally ~1B) with a strong focus on tool-calling capabilities. The goal is to keep all domain knowledge out of the LLM, ensuring it acts as an intelligent agent rather than a static knowledge store.

## Scope & Goals
**Model Size**: Prioritizing models as small as possible (~1B parameters preferred).
**Input Format**: Natural language.
**Functionality Focus**: Strong emphasis on tool-calling efficiency over raw knowledge storage.
**Evaluation Criteria**:
Hardware constraints: Filtering models based on customer requirements.
Open Access (OA) & Licensing considerations.
Specialization: Identifying models optimized for specific tasks.
Performance benchmarks in relevant use cases.
