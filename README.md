# awesome-small-language-model-1B-3B
Efficient (Agentic) Models: Preliminary Literature Search This project explores small-scale, efficient LLMs (1B-3B parameters, ideally ~1B) with a strong focus on tool-calling capabilities. The goal is to keep all domain knowledge out of the LLM, ensuring it acts as an intelligent agent rather than a static knowledge store.
